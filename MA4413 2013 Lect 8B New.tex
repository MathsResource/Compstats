\documentclass[a4]{beamer}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{newlfont}
\usepackage{amsmath,amsthm,amsfonts}
%\usepackage{beamerthemesplit}
\usepackage{pgf,pgfarrows,pgfnodes,pgfautomata,pgfheaps,pgfshade}
\usepackage{mathptmx}  % Font Family
\usepackage{helvet}   % Font Family
\usepackage{color}

\mode<presentation> {
 \usetheme{Default} % was Frankfurt
 \useinnertheme{rounded}
 \useoutertheme{infolines}
 \usefonttheme{serif}
 %\usecolortheme{wolverine}
% \usecolortheme{rose}
\usefonttheme{structurebold}
}

\setbeamercovered{dynamic}

\title[MA4413]{Statistics for Computing \\ {\normalsize MA4413 Lecture 8B}}
\author[Kevin O'Brien]{Kevin O'Brien \\ {\scriptsize Kevin.obrien@ul.ie}}
\date{Autumn Semester 2013}
\institute[Maths \& Stats]{Dept. of Mathematics \& Statistics, \\ University \textit{of} Limerick}

\renewcommand{\arraystretch}{1.5}

%------------------------------------------------------------------------%
\begin{document}
%--------------------------------------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Hypothesis Testing}
\large
Recall: the inferential step to conclude that the null hypothesis is false goes as follows: The data (or data more extreme) are very unlikely given that the null hypothesis is true.
\bigskip
This means that:
\begin{itemize}\item [(1)] a very unlikely event occurred or
\item[(2)] the null hypothesis is false. \end{itemize}
The inference usually made is that the null hypothesis is false. Importantly it doesnÂ’t prove the null hypothesis to be false.
\end{frame}
%-------------------------------------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Type I and II errors}
\large
There are two kinds of errors that can be made in hypothesis testing:
\begin{itemize}
\item[(1)] a true null hypothesis can be incorrectly rejected
\item[(2)] a false null hypothesis can fail to be rejected.
\end{itemize}
The former error is called a \textbf{\emph{Type I error}} and the latter error is called a \textbf{\emph{Type II error}}. \\ \bigskip
The probability of Type I error is always equal to the level of significance $\alpha$ (alpha) that is used as the standard for rejecting the null hypothesis .
\end{frame}
%---------------------------------------------------------------------------%
\begin{frame}
\frametitle{Type II Error}
\begin{itemize}

\item The probability of a Type II error is designated by the Greek letter beta ($\beta$).
\item A Type II error is only an error in the sense that an opportunity to reject the null hypothesis correctly was lost.
\item It is not an error in the sense that an incorrect conclusion was drawn since no conclusion is drawn when the null hypothesis is not rejected.
\end{itemize}
\end{frame}
%---------------------------------------------------------------------------%
\begin{frame}
\frametitle{Types of Error}
\large
\begin{itemize}
\item
A Type I error, on the other hand, is an error in every sense of the word. A conclusion is drawn that the null hypothesis is false when, in fact, it is true. \item Therefore, Type I errors are generally considered more serious than Type II errors.
\item
The probability of a Type I error ($\alpha$ ) is set by the experimenter. \item There is a trade-off between Type I and Type II errors. The more an experimenter protects himself or herself against Type I errors by choosing a low level, the greater the chance of a Type II error.
\end{itemize}
\end{frame}
%---------------------------------------------------------------------------%
\begin{frame}
\frametitle{Types of Error}
\large
\begin{itemize}
\item
Requiring very strong evidence to reject the null hypothesis makes it very unlikely that a true null hypothesis will be rejected. \item However, it increases the chance that a false null hypothesis will not be rejected, thus increasing the likelihood of Type II error.
\item
The Type I error rate is almost always set at 0.05 or at 0.01, the latter being more conservative since it requires stronger evidence to reject the null hypothesis at the 0.01 level then at the 0.05 level.
\item \textbf{Important}In this module, the significance level $\alpha$ can be assumed to be 0.05, unless explicitly stated otherwise.
\end{itemize}
\end{frame}
%---------------------------------------------------------------------------%
\begin{frame}
\frametitle{Type I and II errors}
\large
These two types of errors are defined in the table below.
\small
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
&True State: H0 True & True State: H0 False\\\hline
Decision: Reject H0 & Type I error& Correct\\\hline
Decision: Do not Reject H0 & Correct &Type II error\\ \hline
\end{tabular}
\end{center}
\end{frame}

\begin{frame}
\frametitle{p-values}
\begin{itemize}
\item In hypothesis tests, the difference between the observed value and the parameter value specified by $H_0$ is computed and the probability of obtaining a difference this large or large is calculated.
\item The probability of obtaining data as extreme, or more extreme, than the expected value under the null hypothesis is called the \textbf{\emph{p-value}}.
\item It is not the probability of the null hypothesis itself.
\item Suppose if the probability value is $0.0175$, this does not mean that the probability that the null hypothesis is either true (or false) is $0.0175$.

\end{itemize}
\end{frame}
%--------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{p-values}
\begin{itemize}
\item the p-value means that the probability of obtaining data as different or more different from the null hypothesis as those obtained in the experiment is $0.0175$.
\item If the p-value is less than the specified significance level, adjusted for the number of tails, then we reject the null hypothesis.
\[\mbox{ is p-value} \leq \frac{\alpha}{k} \mbox{?}\]
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{The Hypothesis Testing Procedure }
The second procedures is very similar to the first, but is more practicable for written exams, so we will use this one more. The first two steps are the same.

\begin{itemize}
\item Formally write out the null and alternative hypotheses (already described).
\item Compute the test statistic
\item Determine the \emph{\textbf{critical value}} (described shortly)
\item Make a decision based on the critical value.
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Hypothesis Tests for single samples}

\begin{itemize}
\item We could have inference procedures for single sample studies. We would base an argument on the either the sample mean or sample proportion as appropriate.
\item A hypothesis test can be used to determine how ``confident" we can be with our data in making that statements.
\item The lower the significance level (The margin for Type I error) the stronger our data must be.
\item Large samples lead to more confident conclusion.
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Hypothesis Tests for single samples}
\begin{itemize}
\item We could have either hypothesis test for the sample mean or the sample proportion, to test a statement about the population as a whole (i.e something about the population mean)
\item We make our argument in the form of the null and alternative hypotheses. 
\item The Hypothesis testing procedure determines the strength of evidence in making our arguments. 
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Hypothesis Tests for single samples}
\begin{itemize}
\item We simply follow the four step procedure. 
\item All of the components are the same used in confidence intervals.
\item The critical value is simply a quantile from the $Z$ or $t-$distribution.
\item The standard errors are also as before. Although when performing a hypothesis test for proportions, we use the expected value under the null hypothesis, rather than point estimate. (reason beyond scope of course.)
\end{itemize}
\end{frame}

%--------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 1 (a) Small Sample Hypothesis Test}
\large
\begin{itemize}
%\item The standard deviation of the life for a particular brand of ultraviolet tube is known to
%\item Also it is assumed, but not known, that the operating life of the tubes is normally distributed.

\item The manufacturer claims that average tube life for a particular brand of ultraviolet tube
is 9,000 hr. \item Test this claim at the 5 percent level of significance against the alternative hypothesis
that the mean life is not 9,000 hr \item We are given the following information:  a sample of $n = 10$ tubes the mean operating
life was $\bar{x} = 8,800$ hr. The sample standard deviation is be $s = 500$ hr.
%\item (Intuitively this would suggest a one-tailed test that the mean is less than 9000 hours)
\end{itemize}
\end{frame}


%--------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 1 (b) }
\large
\begin{itemize}
\item $H_0 \mbox{ : } $ $\mu = 9000$ (Average life span is 9000 hours.)
\item $H_1 \mbox{ : } $ $\mu \neq 9000$ (Average life span is not 9000 hours.)
\end{itemize}
\bigskip
\begin{itemize}
\item The observed difference is -200 hours. (i.e. 8,800 - 9,000 hours)
\item The standard error is determined from formulae.
\[ S.E. (\bar{x}) = {s \over \sqrt{n}} = {500 \over \sqrt{10}}  = 158.1139 \]
\end{itemize}
\end{frame}
%--------------------------------------------------------------------------------------%
\begin{frame}[fragile]
\frametitle{Example 1 (c) : Test Statistic and Critical Value }
\large
\[ TS = \frac{8800 - 9000}{158.11} \]
\begin{itemize}
\item The test statistic $TS = -1.265$
\item The CV is determined with $\alpha = 0.05$ and $k = 2$ (column = $\alpha/k=0.025$).
\item The sample is small n = 10 $df = n-1 = 9$ (i.e. row =9).
\item Therefore $CV = 2.262$

\item (Remark: If the sample was large, we could use $CV = 1.96$).

\end{itemize}
\end{frame}

%--------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 1 (d): Decision Rule }
\large
\begin{itemize}
\item \textbf{Decision:}Is $|TS| >CV$? Is $1.265 > 2.262$?
\item No. We fail to reject the null hypothesis. \item There is not enough evidence to say that the mean lifespan is not 9000 hours.
\end{itemize}
\end{frame}


%%%% Type I and Type II errors here
\frame{
\frametitle{The Paired t-test}
A paired t-test is used to compare two population means where you have two samples in
which observations in one sample can be \textbf{\emph{paired}} with observations in the other sample.\\
\bigskip
Examples of where this might occur are:
\begin{itemize}
\item Before-and-after observations on the same subjects (e.g. studentsÂ’ diagnostic test
results before and after a particular module or course).
\item A comparison of two different methods of measurement or two different treatments
where the measurements/treatments are applied to the \textbf{\emph{same}} subjects.
\end{itemize}
The difference between two paired measurements is known as a \textbf{\emph{case-wise}} difference.
}



%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{The Paired t-test}
\begin{itemize}
\item We will often be required to compute the case-wise differences, the average of those differences and the standard deviation of those difference.

\item The mean difference for a set of differences between paired observations is
\[ \bar{d} = {\sum d_i \over n }\]

\item The computational formula for the standard deviation of the differences
between paired observations is
\[s_d = \sqrt{ {\sum d_i^2 - n\bar{d}^2 \over n-1}}\]
\item It is nearly always a small sample test.
\end{itemize}
\end{frame}


%----------------------------------------------------------------------------------------------------%
\frame{
\frametitle{The Paired t-test}
\begin{itemize}
\item $\mu_d$ mean value for the population of case-wise differences.
\item The null hypothesis is that that $\mu_d = 0$
\item Given $\bar{d}$ mean value for the sample of differences, and $s_d$ standard deviation of the differences for the paired sample data, we can compute this test in the same manner as a one-sample test for the mean
\end{itemize}
}

%----------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 2: Paired Difference (a)}
\begin{itemize}
\item An automobile manufacturer collects mileage data for a sample of $n = 10$ cars in various weight categories
using a standard grade of gasoline with and without a particular additive. \item Of course, the engines were tuned to the same
specifications before each run, and the same drivers were used for the two gasoline conditions (with the driver in fact being
unaware of which gasoline was being used on a particular run). \item Given the mileage data on the next slide,  test the hypothesis
that there is no difference between the mean mileage obtained with and without the additive, using the 5 percent level of
significance \end{itemize}
\end{frame}
%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 2: Paired Difference (b)}
\small
\begin{center}
\begin{tabular}{|c|c|c|c|c|}\hline
car & with additive & without additive & $d_i$ & $d^2_i$\\\hline
1&36.7&36.2&0.5&0.25\\\hline
2&35.8&35.7&0.1&0.01\\\hline
3&31.9&32.3&-0.4&0.16\\\hline
4&29.3&29.6&-0.3&0.09\\\hline
5&28.4&28.1&0.3&0.09\\\hline
6&25.7&25.8&-0.1&0.01\\\hline
7&24.2&23.9&0.3&0.09\\\hline
8&22.6&22.0&0.6&0.36\\\hline
9&21.9&21.5&0.4&0.16\\\hline
10&20.3&20.0&0.3&0.09\\\hline
\end{tabular}
\end{center}
\end{frame}

%--------------------------------------------------------------------------------------------------------------------------%
%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 2: Paired Difference (c)}
\begin{itemize}
\item The average of the case wise differences is computed as \[\bar{d} = {\sum d_i \over n}\]
\[ \bar{d} = { 0.05 + 0.1  - 0.4 + \ldots + 0.30 \over 10 }= 0.17 \]
\item Also, using last column, $\sum d^2_i = (0.25 + 0.01 + 0.16 + \ldots + 0.09) = 1.31$
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Example 2: Paired Difference (d)}
\textbf{Sample standard deviation of the case-wise differences}:
\large
\[s_d = \sqrt{ {\sum d_i^2 - n\bar{d}^2 \over n-1}}\]
We know the following:
\begin{itemize}
\item The sample size $n$ which is 10.
\item The average of the case-wise differences. $\bar{d} = 0.17$
\item  $\sum d^2_i = 1.31$
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{Example 2: Paired Difference (e)}
\textbf{Sample standard deviation  of the case-wise differences}://
\[s_d = \sqrt{ {\sum d_i^2 - n\bar{d}^2 \over n-1}}\]

\[s_d = \sqrt{ { 1.31 - 10(0.17)^2 \over 9}} = 0.337\]

\textbf{The standard error:} \[ S.E.(\bar{d}) = s_d / \sqrt{n} = {0.0337 \over 3.16} = 0.107\]
\end{frame}

\begin{frame}
\frametitle{Example 2: Paired Difference (f)}
\textbf{Null and Alternative Hypotheses}:
\begin{itemize}
\item That is, the null hypothesis is:\\
$H_0: \mu_d = 0$ Additive makes no difference to performance\\
$H_1: \mu_d \neq 0$ Additive makes a significant difference to performance \\
\end{itemize}
\textbf{Test Statistic}:
\[ TS = \frac{0.17 - 0}{0.107} = 1.59\]

\end{frame}
\end{document}