\documentclass[a4]{beamer}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{newlfont}
\usepackage{amsmath,amsthm,amsfonts}
%\usepackage{beamerthemesplit}
\usepackage{pgf,pgfarrows,pgfnodes,pgfautomata,pgfheaps,pgfshade}
\usepackage{mathptmx} % Font Family
\usepackage{helvet} % Font Family
\usepackage{color}
\mode<presentation> {
\usetheme{Default} % was Frankfurt
\useinnertheme{rounded}
\useoutertheme{infolines}
\usefonttheme{serif}
%\usecolortheme{wolverine}
% \usecolortheme{rose}
\usefonttheme{structurebold}
}
\setbeamercovered{dynamic}
\title[MA4413]{Statistics for Computing \\ {\normalsize MA4413 Lecture 10A}}
\author[Kevin O'Brien]{Kevin O'Brien \\ {\scriptsize Kevin.obrien@ul.ie}}
\date{Autumn Semester 2013}
\institute[Maths \& Stats]{Dept. of Mathematics \& Statistics, \\ University \textit{of} Limerick}

\renewcommand{\arraystretch}{1.5}
%----------------------------------------------------------------------------------------------------------%
\begin{document}

\begin{frame}
\titlepage
\end{frame}
\begin{frame}
\frametitle{Today's Class}
\begin{itemize}
\item[1] Paired t-test
\item[2] Difference of two mean (large samples)
\item[3] Difference of two mean (small samples)
\item[4] Difference of two proportions
\end{itemize}

\end{frame}
%-------------------------------------------------------------------------------------------%

\begin{frame}
\frametitle{Paired Data}
\begin{itemize}
\item Two measurements are paired when they come from the same case (person, item, observational unit). It is not ncessary for the measurements to be denominated in the same units, but very helpful.
\item Pairing is determined by a study's design and the way the data values are obtained, and with the actual data values themselves not being particularly relevant. 
\item Observations are paired rather than independent when there is a natural link between an observation in one set of measurements and a particular observation in the other set of measurements.
\item Examples of paired data: \textit{\textbf{before and after}} measurements,\textit{ \textbf{with and without}} measurements, and two simultaneous measurements on the same item.
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Paired Data}
\begin{itemize}
\item We are usually required to compute the case-wise difference for each data pairing.
\item Importantly, although we start out with two samples of data, we can look at the data as a single sample of \textit{\textbf{case-wise differences}}.
\[d_i = x_i-y_i\]
\item We can use the same methodologies that we have encountered previously for making decisions based on paired data.
\item (Remark: For most paired data studies, the sample sizes are very small.)
\end{itemize}
\end{frame}
%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{The Paired t-test}
\begin{itemize}
\item We will often be required to compute the case-wise differences, the average of those differences and the standard deviation of those difference.

\item The mean difference for a set of differences between paired observations is
\[ \bar{d} = {\sum d_i \over n }\]

\item The computational formula for the standard deviation of the differences
between paired observations is
\[s_d = \sqrt{ {\sum d_i^2 - n\bar{d}^2 \over n-1}}\]
%\item It is nearly always a small sample test.
\end{itemize}
\end{frame}


%----------------------------------------------------------------------------------------------------%
\frame{
\frametitle{The Paired t-test}
Using the sample to make inferences about the general population of case-wise differences.
\begin{itemize}
\item Often we are making conclusions for the population of differences. (Is a training regime effective? - based on a paired data sample.)
\item Let $\mu_d$ be mean value for the population of case-wise differences.
\item The null hypothesis is that that $\mu_d = 0$ (i.e. no difference)
\item Given $\bar{d}$ mean value for the sample of differences, and $s_d$ standard deviation of the differences for the paired sample data, we can perform inference procedures as we have done previously.
\end{itemize}
}

%----------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 1: Paired Difference (a)}
\begin{itemize}
\item An automobile manufacturer collects mileage data for a sample of $n = 10$ cars in various weight categories
using a standard grade of gasoline with and without a particular additive. \item Of course, the engines were tuned to the same
specifications before each run, and the same drivers were used for the two gasoline conditions (with the driver in fact being
unaware of which gasoline was being used on a particular run). \item Given the mileage data on the next slide,  test the hypothesis
that there is no difference between the mean mileage obtained with and without the additive, using the 5 percent level of
significance \item (Remark in lecture: Enough evidence for haulage company to start buying this additive?) \end{itemize}
\end{frame}
%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 1: Paired Difference (b)}
\small
\begin{center}
\begin{tabular}{|c|c|c|c|c|}\hline
car & with additive & without additive & $d_i$ & $d^2_i$\\\hline
1&36.7&36.2&0.5&0.25\\\hline
2&35.8&35.7&0.1&0.01\\\hline
3&31.9&32.3&-0.4&0.16\\\hline
4&29.3&29.6&-0.3&0.09\\\hline
5&28.4&28.1&0.3&0.09\\\hline
6&25.7&25.8&-0.1&0.01\\\hline
7&24.2&23.9&0.3&0.09\\\hline
8&22.6&22.0&0.6&0.36\\\hline
9&21.9&21.5&0.4&0.16\\\hline
10&20.3&20.0&0.3&0.09\\\hline
\end{tabular}
\end{center}
\end{frame}

%--------------------------------------------------------------------------------------------------------------------------%
%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 1: Paired Difference (c)}
\begin{itemize}
\item The average of the case wise differences is computed as \[\bar{d} = {\sum d_i \over n}\]
\[ \bar{d} = { 0.5 + 0.1  - 0.4 + \ldots + 0.30 \over 10 }= 0.17 \]
\item Also, using last column, $\sum d^2_i = (0.25 + 0.01 + 0.16 + \ldots + 0.09) = 1.31$
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Example 1: Paired Difference (d)}
\textbf{Sample standard deviation of the case-wise differences}:
\large
\[s_d = \sqrt{ {\sum d_i^2 - n\bar{d}^2 \over n-1}}\]
\vspace{0.2cm}
We know the following:
\begin{itemize}
\item The sample size $n$ which is 10.
\item The average of the case-wise differences. $\bar{d} = 0.17$
\item  $\sum d^2_i = 1.31$
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{Example 1: Paired Difference (e)}
\textbf{Sample standard deviation  of the case-wise differences}:
\[s_d = \sqrt{ {\sum d_i^2 - n\bar{d}^2 \over n-1}}\]

\[s_d = \sqrt{ { 1.31 - 10(0.17)^2 \over 9}} = 0.337\]

\textbf{The standard error:} \[ S.E.(\bar{d}) = \frac{s_d }{\sqrt{n}} = {0.337 \over 3.16} = 0.107\]
\end{frame}

\begin{frame}
\frametitle{Example 1: Paired Difference (f)}
\textbf{Null and Alternative Hypotheses}:
\begin{itemize}
\item That is, the null hypothesis is:\\
$H_0: \mu_d = 0$ Additive makes no difference to performance\\
$H_1: \mu_d \neq 0$ Additive makes a significant difference to performance \\
\end{itemize}
\vspace{0.5cm}
\textbf{Test Statistic}:
\begin{itemize}
\item Test Statistic
\[TS =\frac{\bar{d} - \mu_d}{S.E.(\bar{d})} =  \frac{0.17 - 0}{0.107} = 1.59\]
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Example 1: Paired Difference (g)}
\textbf{Critical value}:
\begin{itemize}
\item $\alpha = 0.05, k = 2$ \item small sample , so $df = n-1 = 9$
\item As with earlier examples in the course, CV is found to be \textbf{2.262} from the statistical tables.
\end{itemize}
\bigskip
\textbf{Decision Rule}:\\
Is $|TS| > CV$? \\ No, we fail to reject the null hypothesis.
There is no enough evidence to suggest this additive is effective in improving mileages for automobiles.
\end{frame}

\begin{frame}
\frametitle{Example 1: Paired Difference (h)}
\textbf{Confidence Interval}:
\begin{itemize}
\item Recall our sample mean $\bar{x}$, the standard error $S.E(\bar{x})$ and the quantile from the $t-$ distribution.
\item We can use these values to compute a 95\% confidence interval.
\item The 95\% confidence interval can be computed as $0.17 \pm (2.262 \times 0.17 = (-0.21,0.55)$
\item Notice that 0 is within that range of values. This supports our conclusion to reject the Null Hypothesis.
\end{itemize}
\end{frame}
\begin{frame}
\textbf{Two Sample Procedures}
\begin{itemize}
\item So far we have looked at single sample procedures.
\item We can generalise our methodologies for comparing two samples.
\item Our point estimates are typically differences in sample statistics. i.e.
\[ \bar{X}_1 - \bar{X}_2\]
\[\hat{p}_1 - \hat{p}_2 \]
\item We can use these point estimates to make inference on differences for populations.
\[ \mu_1 - \mu_2\]
\[ \pi_1 - \pi_2 \]
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Two Sample Procedures - Confidence Intervals}
\begin{itemize}
\item When computing confidence intervals, all that is required is the calculation of the appropriate standard error value.
\item The two-sample standard error calculations contain statistical information from both samples.
\item See the formula sheet. (Practice with these calculaions will take place in next week's tutorials.)
\item There are some minor issues that will arise with each type of procedure. These will be explained in relevant examples.
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Two Sample Procedures - small samples and degrees of freedom}
\begin{itemize}
\item Let $n_1$ and $n_2$ be the sample sizes of two samples.
\item When deciding whether to use the large sample approach or the small sample appproach, we will use the following rule of thumb: \\
Small sample : $n_1+n_2 \leq 30$\\
Large sample : otherwise\\
\item For small samples the appropriate degrees of freedom is $(n_1-1) + (n_2-1)$ i.e. $n_1 + n_2-2$ 
\end{itemize}
\end{frame}
\begin{frame}
\textbf{Two Sample Procedures - small samples and degrees of freedom}
\begin{itemize}
\item When performing hypothesis tests, we are usually interested in determining whether or not the population parameters can be considered equal for both populations.
\item Another way of expressing this is that the difference in population parameters is 0. 
\item The following two hypotheses are directly equivalent.
\[ H_o :  \mu_1 = \mu_2\]
\[ H_o :  \mu_1 - \mu_2 =0\]
\item Equivalently, for proportions:
\[ H_o :  \pi_1 = \pi_2\]
\[ H_o :  \pi_1 - \pi_2 =0\]
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Two Sample Procedures - Standard Errors}
\begin{itemize}
\item \textbf{Small Samples}: When computing the standard error for difference in sample means - take care to use the appropriate standard error formula. (i.e using the pooled variance calculation.)
\item \textbf{Hypothesis Tests for Propostions:} Use the aggregate proportion formula $\bar{p}$.
\item See formula sheet.
\end{itemize}
\end{frame}
%--------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 2: Difference in Means (a) }
\begin{itemize}
\item Two sets of patients are given courses of treatment under two different drugs. \item 
The benefits
derived from each drug can be stated numerically in terms of the recovery times measured in days
\item The sample size, mean and standard deviations for both groups are given below.
\end{itemize}
\begin{tabular}{|c|c|c|c|}
\hline Group & Sample Size & Mean & Std. Dev.  \\ 
\hline 1 & $n_1$ = 40 & $\bar{x}_1$ = 3.3 days  &  $s_1 = 1.524$ \\ 
\hline 2 & $n_2$ = 45 & $\bar{x}_2$ = 4.3 days & $s_2 = 1.951 $ \\ 
\hline 
\end{tabular} 

\end{frame}

%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 2: Difference in Means (b) }
\begin{itemize}
\item
The first step in hypothesis testing is to specify the null hypothesis and an alternative hypothesis.
\item When testing differences between mean recovery times, the null hypothesis is that the two population means are equal.
\item That is, the null hypothesis is:\\
$H_0: \mu_1 = \mu_2$ (The population means are equal - no difference in drug treatments)\\
$H_1: \mu_1 \neq \mu_2$ (The population means are different - difference in drug treatments)\\
\end{itemize}
(Remark: Two-tailed Test, therefore $k = 2$, and $\alpha = 0.05$)
\end{frame}

%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 2: Difference in Means (c) }
\begin{itemize}
\item \textbf{Point Estimate}: The observed difference in means is $\bar{x}_1-\bar{x}_2 \;= \;4.3-3.3 \;$= 1 day.
\vspace{0.2cm}
\item The relevant formula for the standard error is
\[ S.E(\bar{x}_1 - \bar{x}_2) = \sqrt{{s^2_1\over n_1}+{s^2_2 \over n_2}} \]
 \[ S.E(\bar{x}_1 - \bar{x}_2) = \sqrt{{(1.524)^2 \over 40}+{(1.951)^2 \over 45}}   \]\vspace{0.2cm}
 \[ S.E(\bar{x}_1 - \bar{x}_2) = 0.377\mbox{ days}\]
\end{itemize}
\end{frame}

%-------------------------------------------------------------------------------------------%
\begin{frame}[fragile]
\frametitle{Example 2: Difference in Means (d) }
\vspace{-1cm}
\begin{itemize}
\item The Test statistic is therefore
\[ TS = {\mbox{Point Estimate} - \mbox{Difference under } H_0 \over \mbox{Std. Error}} \]

\[TS = {1 - 0 \over 0.377 } = 2.65 \]


\end{itemize}
\end{frame}


%-------------------------------------------------------------------------------------------%
\begin{frame}[fragile]
\frametitle{Example 2: Difference in Means (e) }
\vspace{-1cm}
\begin{itemize}
\item As the sample was large, we could use $CV = 1.96$ (as always, two tailed procedure, with $\alpha=0.05$).

\item \textbf{Decision Rule}: Is the $TS > CV$ ? \\  Is $2.65 > 1.96$ ? - Yes , we reject the null hypothesis.
\item There is enough evidence to suggest that there is a difference in drug treatments.
\end{itemize}
\end{frame}




%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 3: Difference in Means (a) }
\vspace{-1cm}
\begin{itemize}
\item For a random sample of 10 light bulbs, the mean bulb life is 4,000 hr with a standard deviation of 200 hours.
\item For another brand of bulbs whose useful life is also assumed to be normally distributed, a random sample of 8 has a sample mean of 4,300 hours
and a sample standard deviation of 250 hours. \item Test the hypothesis that there is no difference between the
mean operating life of the two brands of bulbs, using the 5 percent level of significance.
\end{itemize}
\end{frame}
%-------------------------------------------------------------------------------------------%

\begin{frame}
\frametitle{Example 3: Difference in Means (b) }
\textbf{Summary of Information}
\begin{itemize}\item $n_1 = 10$ and $n_2 = 8$.
\item $\bar{x}_1 = 4000$ hours, $\bar{x}_2 = 4,300 $ hours , therefore  $\bar{x}_2 - \bar{x}_1 = 300$ hours
\item $s_1  = 200$ hours, $s_2 = 250$ hours.
\item Small aggregate sample - Degrees of freedom $n_1 + n_2 - 2 = 10 + 8 - 2 = 16$
\end{itemize}\end{frame}
%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 3: Difference in Means (c) }
\begin{itemize}
\item Look at the standard error formula for difference in means for a small aggregate sample.
\item Before we compute the standard error, we must compute the \textbf{pooled variance estimate}
\end{itemize}
\[ s^2_p = {(n_1 - 1)s^2_1  + (n_2 - 1)s^2_ 2\over n_1 + n_2 - 2 } \]\[s^2_p = {(9 \times 200^2 ) +( 7 \times 250^2) \over 16 }  \]
\[ s^2_p  = 49843.75 \]
\end{frame}

%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 3: Difference in Means (d) }
\textbf{Computing the Standard Error}
\[ S.E(x_1 - x_2) = \sqrt{s^2_p \left({1\over n_1}+{1\over n_2} \right)}\]

\[ S.E(x_1 - x_2) = \sqrt{49843.75 \left({1\over 10}+{1\over 8} \right)}\]

\[ S.E(x_1 - x_2) = \sqrt{11214.84} = 105.9\]

\end{frame}

%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 3: Difference in Means (e) }
\textbf{Test Statistic and Critical Value}\\
\begin{itemize}
\item The Test Statistic (usual structure) is \[ TS  = {(-300) - 0 \over 105.9}  = -2.83 \]
\item The Critical Value is determined  with $\alpha = 0.05$, $k=2$, $df = 16 $. 
\item From statistical tables: $CV = 2.120$
\item We can now apply the decision rule : Is the absolute value of the Test Statistic greater than the Critical Value?
\item Is $2.83 > 2.12$? Yes We reject $H_0$. There is evidence of a difference in means. 
\item There is enough evidence to suggest that there is a difference in lifespans for the two brands.
\end{itemize}
\end{frame}



%-------------------------------------------------------------------------------------------%

\begin{frame}
\frametitle{Example 4: Difference in Proportions (a)}
\begin{itemize}
\item An experiment is conducted investigating the long-term effects of early childhood intervention programs (such as head start).
\item In one experiment, the high-school drop out rate of the \textit{\textbf{experimental group}} (which attended the early childhood program)
 and the \textit{\textbf{control group}} (which did not) were compared.
\item In the experimental group, 73 of 85 students graduated from high school. \item In the control group, only 43 of 82 students graduated.
Is this difference statistically significant? \item(For this procedure, you may assume that the 0.05 level is chosen.) \end{itemize}
\end{frame}

%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 4: Difference in Proportions (b)}
\vspace{-1cm}
\begin{itemize}
\item
The first step in hypothesis testing is to specify the null hypothesis and an alternative hypothesis.
\item When testing differences between proportions, the null hypothesis is that the two population proportions are equal.
\item That is, the null hypothesis is:\\
$H_0: \pi_1 = \pi_2$\\
$H_1: \pi_1 \neq \pi_2$\\
\item (Remark: Two Tailed Test k = 2, and $\alpha = 0.05$)
\end{itemize}

\end{frame}
%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 4: Difference in Proportions (c)}
\vspace{-1cm}
\begin{itemize}
\item The next step is to compute the difference between the sample proportions.
\item In this example, The point estimat is $\hat{p}_1 - \hat{p}_2$ 
\[\hat{p}_1 - \hat{p}_2 = \frac{73}{85} - \frac{43}{82} = 0.8588 - 0.5244\].
\item $\hat{p}_1 - \hat{p}_2$ =  0.3344.
\item Difference in sample proportions is $33.44\%$
\end{itemize}
\end{frame}



%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 4: Difference in Proportions (d)}
\vspace{-1cm}
The formula for the estimated standard error is:

\[ S.E (\hat{p}_1 - \hat{p}_2)  = \sqrt{\bar{p} \left( {1 \over n_1} + {1 \over n_2}  \right)} \]


where $\bar{p}$ is a \textit{\textbf{aggregate proportion}} (proportion of successes from overall sample, regardless of which group they are in).
\\
(see next slide.)
\end{frame}

%-------------------------------------------------------------------------------------------%




\begin{frame}
\frametitle{Example 4: Difference in Proportions (d)}
\textbf{Aggregate Proportion}:\\
\[ \bar{p}  = {x_1  + x_2 \over n_1 + n_2} \times 100\% = {73+43 \over 85 + 82} \times 100\% = { 116 \over 167}\times 100\% = 69.5\% \]
\textbf{Standard Error}:\\
\[ S.E (\hat{p}_1 - \hat{p}_2)  =  \sqrt{69.5 \times 30.5  \left( {1 \over 85} + {1 \over 82}  \right)}  = 7.13\% \]

\end{frame}



%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 4: Difference in Proportions (e)}
\textbf{Test Statistic}:
\begin{itemize} \item Observed difference :
85.88\% - 52.44\%  = 33.44\% \item Calculation \[ i.e (73/85) - (43 /82) \]
\item Under the null hypothesis, the expected difference is zero.
\item Test Statistic is therefore \[T.S. = {33.44\% \over 7.13\%} = 4.69\]
\end{itemize}

\end{frame}
%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Example 4: Difference in Proportions (e)}
\begin{itemize}
\item The Critical value is 1.96 (Large sample , $\alpha = 0.05$, k=2).

\item The test statistic TS = 4.69, is greater than the critical value CV = 1.96, so we reject the null hypothesis.
\item The conclusion is that the probability of graduating from high school is greater for students who have participated in the early childhood intervention program than for students who have not.
\end{itemize}

\end{frame}



\end{document}




